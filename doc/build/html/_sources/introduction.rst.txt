.. _introduction:

Introduction
============

@node Description
@section Description

FEPX is a finite element software package for polycrystal plasticity. It is well-suited to model the global and local mechanical behavior of large polycrystalline solids as aggregates of grains as well as associated microstructural evolution through a highly scalable parallel framework. Each grain is discretized by finite elements whose local behavior corresponds accordingly to the local behavior of a sub-volume of a crystal. These behaviors include:

@itemize

@item Nonlinear kinematics capable of resolving large (or finite) strains and large rotations,

@item Anisotropic elasticity based on crystal symmetry,

@item Anisotropic plasticity based on rate-dependent slip restricted to dominant slip systems,

@item Appropriate state variable evolution for crystal lattice orientation and slip system strengths.

@end itemize

FEPX strives to be a user-friendly, efficient, and robust tool. All of the input data are prescribed non-interactively, using ASCII files. FEPX works hand in hand with Neper (@url{https://neper.info}), which can be used for both generating the input polycrystal mesh and post-processing the simulation results. Currently, FEPX is designed to provide solutions on rectangular prismatic domains (or right cuboids).

@node Resources and Support
@section Resources and Support

Several complementary resources describing FEPX are available:

@itemize

@item The FEPX reference manual, the document you are reading, provides a detailed overview of all of FEPX's capabilities. Specific chapters are dedicated to simulation input and output, running simulations, and various example simulations.

@item The FEPX theory manual, written by Paul Dawson and Donald Boyce, provides in depth details on the underlying mechanical theory and finite element methods utilized in FEPX. It is available at @url{https://arxiv.org/abs/1504.03296}.@footnote{Please note that the descriptions of simulation input and output provided in the FEPX theory manual are no longer up-to-date and the user is instead recommended to utilize the descriptions provided in the FEPX reference manual.}

@item The FEPX website, @url{https://fepx.info}, gives a general introduction to FEPX with illustrative examples.

@item The FEPX GitHub repository, @url{https://github.com/acmelab-ua/FEPX}, is where the latest version is available and where user interactions take place:

@itemize
@item To get and keep up-to-date with the latest version, clone the repository using

@com{git clone https://github.com/acmelab-ua/FEPX.git}

which gives access to the latest stable development release on the default, @code{main} branch. To update your local repository, run @command{git pull} from within the repository.

@item To report bugs, use the issue tracker, @url{https://github.com/acmelab-ua/FEPX/issues}. When reporting bugs, please provide a minimal working example and the FEPX terminal output.

@item To ask questions, share comments or request new features, use discussions, @url{https://github.com/acmelab-ua/FEPX/discussions}.

@end itemize

@end itemize

Resources for Neper can be accessed from @url{https://neper.info}.

@node Installing FEPX
@section Installing FEPX

FEPX is written in Fortran, and it can run on any Unix-like system (including MacOS). Parallelization of the code is achieved via OpenMPI. Compilation is performed via CMake:

@itemize
@item Create a @file{build} directory, for instance as a subdirectory of FEPX's @file{src} directory

@com{mkdir build}

@item Run CMake from within the @file{build} directory, pointing to FEPX's @file{src} directory

@com{cd build}
@com{cmake ..}

@item Build FEPX

@com{make}

@item Install FEPX on your system (as root)
@com{make install}

@end itemize

This procedure uses the default configuration options and should work out-of-the-box if you have a Fortran compiler, OpenMPI, and CMake installed. Testing is performed on GFortran @w{version 6} and greater, and OpenMPI @w{version 2} and greater (other Fortran compilers and MPI distributions may also work, though they are not explicitly supported or tested by ACME Lab). A minimum version of CMake @w{version 3.0} is required to utilize the build system.

@node Testing FEPX
@section Testing FEPX

FEPX comes packaged with tests and reference outputs. To run the tests, execute the following from your build folder:
@com{make test}

or (equivalently)
@com{ctest}

This runs the tests in @dfn{Normal} mode, for which the produced output files are compared to reference ones.
@c
The (packaged) reference output files are generated on @w{Ubuntu 20.04}, using compiler @w{GFortran 9.3.0} and @w{OpenMPI 4.0.3} (note: CMake will switch to the MPI Fortran compiler to build FEPX, which will be built against GFortran 9.3.0). It is expected that different versions may result in minor (insignificant) changes to the output, though this will generally result in failed tests.  If this happens, you may switch to the @dfn{Minimal} mode as described in the following.

The testing mode is controlled by variable @code{BUILD_TESTING_MODE}, which may be changed using

@comc{ccmake ..@ @ @ , (for an interactive command-line tool)}

or

@comc{cmake-gui .., (for an interactive graphical tool)}

or directly at the command line, using @code{cmake}'s @code{-D} option,

@com{cmake -DBUILD_TESTING_MODE=@{Normal,Minimal,Writing@} ..}

@sp 1
@itemize
@item The (default) @code{Normal} mode checks if the program completes without error and if the produced output is the same as a set of reference output.

@item The @code{Minimal} mode only checks if the program completes without error. This mode may be useful when installing on a machine which has program or library versions different from the ones with which the reference output was generated.

@item The @code{Writing} mode overwrites the reference outputs with the generated output.  This mode may be useful when installing on a machine which has program or library versions different from the ones with which the reference output was generated and the user needs a reference output before making changes to the source code.
@end itemize

@node Getting Started
@section Getting Started

To run a serial simulation on a local computer, the @samp{fepx} binary must be run in a terminal,

@com{fepx}

or, for parallel simulations,

@com{mpirun -np @var{N} fepx}

where @var{N} refers to the number of MPI processes (typically equal to or less than the number of cores on the local machine). The @samp{fepx} binary should always be run from within a simulation directory that contains the necessary simulation input files (@pxref{Simulation Input}).

To perform simulations across multiple computational nodes on an HPC cluster, a submission script that conforms to the specific job scheduling program is necessary. Examples of generic scripts for common job scheduling programs are detailed in @ref{Running a Simulation}.

During a simulation run, FEPX returns real-time messages in the terminal and, upon successful completion, prints requested output data in ASCII files.

@section Reading this Manual

This manual is maintained as a Texinfo manual. Here are the writing conventions used in the document:

@itemize
@item A command that can be typed in a terminal is printed like @command{this}, or, in the case of a major command, like

@comc{this,;}

@item A program (or command) option is printed like @option{this};
@item The name of a variable is printed like @code{this};
@item A meta-syntactic variable (i.e.@: something that stands for another piece of text) is printed like @var{this};
@item Literal examples are printed like @samp{this};
@item File names are printed like @file{this}.
@end itemize

Additionally, hereinafter a @dfn{core} will explicitly refer to a processor (or CPU) of a computer. This terminology is also consistent with file name formatting for parallel simulation output by FEPX.

@node S1 Development History
@section Development History

The development of FEPX began in the late 1990s and was lead by Paul Dawson, and involved many members of the Deformation Process Laboratory (DPLab) at Cornell University, until early 2020.  An extended development history contributed by Paul Dawson, the lead investigator of the DPLab, can be found in @ref{Development History}.
Ongoing development has since been lead by Matthew Kasemer, and involved other members of the Advanced Computational Materials Engineering Laboratory (ACME Lab) at The University of Alabama.
